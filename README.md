# Aurebesh OCR

This project provides an OCR pipeline for recognizing Aurebesh, the fictional script from STAR WARS. Built on the [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) framework, it enables training, inference of Aurebesh.

## Features

This OCR is powered by PaddleOCR models.

| Stage | Base Model |
|---|---|
| **Detection** | **PP-OCRv5_mobile_det** |
| **Recognition** | **en_PP-OCRv5_mobile_rec** |

## System Specifications

This project was developed and tested on the following hardware configuration:

- **Chip**: Apple M4 Pro
- **Memory**: 48GB

## Installation

Install PaddlePaddle refer to [Installation Guide](https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html), after then, install the PaddleOCR toolkit.

```bash
# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series
python -m pip install paddleocr
# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.
# python -m pip install "paddleocr[all]"
```

Starting from version 3.2.0, in addition to the `all` dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:

| Dependency Group Name | Corresponding Functionality |
| - | - |
| `doc-parser` | Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3 |
| `ie` | Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4 |
| `trans` | Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation |
| `all` | Complete functionality |

## File Preparation

### Dataset

**Detector dataset** can be generated by [SynthText-docker](https://github.com/ShimeiYago/SynthText-docker). Run exporting script for PaddleOCR finally and place it to `train_data/aurebesh/det/` in this repository.

**Recognizer dataset** can be generated by [synthtiger-aurebesh](https://github.com/ShimeiYago/synthtiger-aurebesh). Run exporting script for PaddleOCR finally and place it to `train_data/aurebesh/rec/` in this repository.

```
train_data/
└── aurebesh/
  ├── det/
  │   ├── images/
  │   ├── train.txt
  │   └── val.txt
  └── rec/
      ├── dict.txt
      ├── images/
      ├── train.txt
      └── val.txt
```

### Pre-trained models

```bash
# download detector pretrained model (PP-OCRv5_mobile_det)
wget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/PP-OCRv5_mobile_det_pretrained.pdparams -P pretrained_models/

# download recognizer pretrained model (en_PP-OCRv5_mobile_rec)
wget https://paddle-model-ecology.bj.bcebos.com/paddlex/official_pretrained_model/en_PP-OCRv5_mobile_rec_pretrained.pdparams -P pretrained_models/
```

## Training

### Train detector

```bash
python3 tools/train.py -c configs/det/PP-OCRv5/aurebesh_PP-OCRv5_mobile_det.yml -o Global.use_gpu=false
```

### Train recognizer

```bash
python3 tools/train.py -c configs/rec/PP-OCRv5/multi_language/aurebesh_PP-OCRv5_mobile_rec.yaml -o Global.use_gpu=false
```

## License
This project is released under the [Apache 2.0 license](LICENSE).
